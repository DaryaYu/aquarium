{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classical Deep Learning for Recommendation\n",
    "\n",
    "Exploration of two neural recommender models on MovieLens 1M:\n",
    "- **NeuralMF** (explicit rating prediction)\n",
    "- **TwoTowerBPR** (implicit pairwise ranking)\n",
    "\n",
    "Both models use the same temporal data split and evaluation metrics as the classical MF/BPR baselines in this repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "sys.path.append(str(PROJECT_ROOT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0xffff3cb237b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from src.data_reading import read_ratings_file\n",
    "from src.evaluation import (\n",
    "    temporal_split,\n",
    "    evaluate_rmse,\n",
    "    evaluate_mae,\n",
    "    evaluate_precision_at_k,\n",
    "    evaluate_recall_at_k,\n",
    "    evaluate_ndcg_at_k,\n",
    ")\n",
    "from src.models.neural_mf import NeuralMF\n",
    "from src.models.two_tower_bpr import TwoTowerBPR\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and temporal split\n",
    "\n",
    "We follow the same **temporal split** strategy as the ALS experiment:\n",
    "train on the past, validate in the middle slice, and test on the most recent\n",
    "interactions to mimic realistic deployment conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1000209 ratings\n",
      "Train set size: (700148, 4)\n",
      "Validation set size: (100020, 4)\n",
      "Test set size: (200041, 4)\n",
      "Train timeframe: 2000-04-25 23:05:32 - 2000-11-22 03:06:26\n",
      "Val timeframe: 2000-11-22 03:06:30 - 2000-12-02 14:52:18\n",
      "Test timeframe: 2000-12-02 14:52:28 - 2003-02-28 17:49:50\n",
      "Train size: (700148, 4)\n",
      "Val size: (26246, 4)\n",
      "Test size: (84804, 4)\n"
     ]
    }
   ],
   "source": [
    "ratings = read_ratings_file()\n",
    "print(f\"Loaded {len(ratings)} ratings\")\n",
    "\n",
    "train, val, test = temporal_split(ratings, test_ratio=0.2, val_ratio=0.1)\n",
    "train_users = train.user_id.unique()\n",
    "train_movies = train.movie_id.unique()\n",
    "\n",
    "val = val[(val.user_id.isin(train_users)) & (val.movie_id.isin(train_movies))]\n",
    "test = test[(test.user_id.isin(train_users)) & (test.movie_id.isin(train_movies))]\n",
    "\n",
    "print(\"Train size:\", train.shape)\n",
    "print(\"Val size:\", val.shape)\n",
    "print(\"Test size:\", test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ID reindexing and PyTorch datasets\n",
    "\n",
    "We map `user_id` and `movie_id` to contiguous integer indices for efficient\n",
    "embedding lookups and define simple `Dataset` wrappers for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_users=4870, n_items=3633\n"
     ]
    }
   ],
   "source": [
    "\n",
    "user_ids = train['user_id'].unique()\n",
    "item_ids = train['movie_id'].unique()\n",
    "\n",
    "user_map = {uid: i for i, uid in enumerate(user_ids)}\n",
    "item_map = {mid: i for i, mid in enumerate(item_ids)}\n",
    "\n",
    "train['u_idx'] = train['user_id'].map(user_map)\n",
    "train['i_idx'] = train['movie_id'].map(item_map)\n",
    "val = val.copy()\n",
    "val['u_idx'] = val['user_id'].map(user_map)\n",
    "val['i_idx'] = val['movie_id'].map(item_map)\n",
    "test = test.copy()\n",
    "test['u_idx'] = test['user_id'].map(user_map)\n",
    "test['i_idx'] = test['movie_id'].map(item_map)\n",
    "\n",
    "train = train.dropna(subset=['u_idx', 'i_idx'])\n",
    "val = val.dropna(subset=['u_idx', 'i_idx'])\n",
    "test = test.dropna(subset=['u_idx', 'i_idx'])\n",
    "\n",
    "n_users = len(user_map)\n",
    "n_items = len(item_map)\n",
    "print(f\"n_users={n_users}, n_items={n_items}\")\n",
    "\n",
    "\n",
    "class ExplicitRatingsDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.u = df['u_idx'].astype(int).values\n",
    "        self.i = df['i_idx'].astype(int).values\n",
    "        self.r = df['rating'].astype(float).values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.r)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            torch.tensor(self.u[idx], dtype=torch.long),\n",
    "            torch.tensor(self.i[idx], dtype=torch.long),\n",
    "            torch.tensor(self.r[idx], dtype=torch.float32),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: NeuralMF (explicit rating prediction)\n",
    "\n",
    "A non-linear generalization of matrix factorization that replaces the\n",
    "single dot-product with an MLP over concatenated user/item embeddings.\n",
    "We optimize **MSE loss** on explicit ratings and evaluate with RMSE/MAE\n",
    "and ranking metrics (Precision@K, Recall@K, NDCG@K)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - train MSE: 3.3552, val RMSE: 0.9555\n",
      "Epoch 2/5 - train MSE: 0.9673, val RMSE: 0.9450\n",
      "Epoch 3/5 - train MSE: 0.9548, val RMSE: 0.9424\n",
      "Epoch 4/5 - train MSE: 0.9413, val RMSE: 0.9385\n",
      "Epoch 5/5 - train MSE: 0.9282, val RMSE: 0.9362\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4096\n",
    "lr = 1e-3\n",
    "n_epochs = 5\n",
    "\n",
    "train_ds = ExplicitRatingsDataset(train)\n",
    "val_ds = ExplicitRatingsDataset(val)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_nmf = NeuralMF(n_users=n_users, n_items=n_items, embed_dim=32, hidden_dims=(64, 32), dropout=0.1)\n",
    "model_nmf.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model_nmf.parameters(), lr=lr)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    model_nmf.train()\n",
    "    total_loss = 0.0\n",
    "    for u, i, r in train_loader:\n",
    "        u = u.to(device)\n",
    "        i = i.to(device)\n",
    "        r = r.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        preds = model_nmf(u, i)\n",
    "        loss = criterion(preds, r)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * len(r)\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_ds)\n",
    "\n",
    "    model_nmf.eval()\n",
    "    with torch.no_grad():\n",
    "        sq_errors = []\n",
    "        for u, i, r in val_loader:\n",
    "            u = u.to(device)\n",
    "            i = i.to(device)\n",
    "            r = r.to(device)\n",
    "            preds = model_nmf(u, i)\n",
    "            sq_errors.append((preds - r).pow(2).cpu().numpy())\n",
    "        val_rmse = np.sqrt(np.concatenate(sq_errors).mean())\n",
    "\n",
    "    print(f\"Epoch {epoch}/{n_epochs} - train MSE: {avg_train_loss:.4f}, val RMSE: {val_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralMF - Test RMSE: 0.9371\n",
      "NeuralMF - Test MAE:  0.7358\n"
     ]
    }
   ],
   "source": [
    "model_nmf.eval()\n",
    "\n",
    "def nmf_predict_rating(user_id: int, movie_id: int, model, user_map, item_map) -> float:\n",
    "    if user_id not in user_map or movie_id not in item_map:\n",
    "        return float(\"nan\")\n",
    "\n",
    "    u_idx = torch.tensor([user_map[user_id]], dtype=torch.long, device=device)\n",
    "    i_idx = torch.tensor([item_map[movie_id]], dtype=torch.long, device=device)\n",
    "    with torch.no_grad():\n",
    "        pred = model(u_idx, i_idx).cpu().item()\n",
    "    return float(pred)\n",
    "\n",
    "rmse_nmf = evaluate_rmse(test, nmf_predict_rating, model=model_nmf, user_map=user_map, item_map=item_map)\n",
    "mae_nmf = evaluate_mae(test, nmf_predict_rating, model=model_nmf, user_map=user_map, item_map=item_map)\n",
    "\n",
    "print(f\"NeuralMF - Test RMSE: {rmse_nmf:.4f}\")\n",
    "print(f\"NeuralMF - Test MAE:  {mae_nmf:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralMF - Precision@10: 0.0252\n",
      "NeuralMF - Recall@10:    0.0044\n",
      "NeuralMF - NDCG@10:      0.0160\n"
     ]
    }
   ],
   "source": [
    "rain_user_items = train.groupby('user_id')['movie_id'].apply(set).to_dict()\n",
    "all_candidate_items = np.array(list(item_map.keys()))\n",
    "\n",
    "def nmf_recommend_k(\n",
    "    user_id: int,\n",
    "    k: int,\n",
    "    model,\n",
    "    user_map,\n",
    "    item_map,\n",
    "    test: pd.DataFrame | None = None,\n",
    ") -> np.ndarray:\n",
    "    if user_id not in user_map:\n",
    "        return np.array([], dtype=int)\n",
    "\n",
    "    u_idx = user_map[user_id]\n",
    "\n",
    "    if test is not None:\n",
    "        candidate_items = np.intersect1d(test.movie_id.unique(), all_candidate_items)\n",
    "    else:\n",
    "        candidate_items = all_candidate_items\n",
    "\n",
    "    if len(candidate_items) == 0:\n",
    "        return np.array([], dtype=int)\n",
    "\n",
    "    seen_items = train_user_items.get(user_id, set())\n",
    "    candidate_items = np.setdiff1d(candidate_items, np.array(list(seen_items), dtype=int))\n",
    "    if len(candidate_items) == 0:\n",
    "        return np.array([], dtype=int)\n",
    "\n",
    "    item_indices = [item_map[mid] for mid in candidate_items if mid in item_map]\n",
    "    if not item_indices:\n",
    "        return np.array([], dtype=int)\n",
    "\n",
    "    u_tensor = torch.full((len(item_indices),), u_idx, dtype=torch.long, device=device)\n",
    "    i_tensor = torch.tensor(item_indices, dtype=torch.long, device=device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        scores = model(u_tensor, i_tensor).cpu().numpy()\n",
    "\n",
    "    top_k_idx = np.argsort(scores)[::-1][:k]\n",
    "    return candidate_items[top_k_idx]\n",
    "\n",
    "\n",
    "prec_nmf = evaluate_precision_at_k(test, nmf_recommend_k, k=10, model=model_nmf, user_map=user_map, item_map=item_map)\n",
    "recall_nmf = evaluate_recall_at_k(test, nmf_recommend_k, k=10, model=model_nmf, user_map=user_map, item_map=item_map)\n",
    "ndcg_nmf = evaluate_ndcg_at_k(test, nmf_recommend_k, k=10, model=model_nmf, user_map=user_map, item_map=item_map)\n",
    "\n",
    "print(f\"NeuralMF - Precision@10: {prec_nmf:.4f}\")\n",
    "print(f\"NeuralMF - Recall@10:    {recall_nmf:.4f}\")\n",
    "print(f\"NeuralMF - NDCG@10:      {ndcg_nmf:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: TwoTowerBPR (implicit pairwise ranking)\n",
    "\n",
    "A two-tower embedding model optimized with a **BPR-style pairwise loss** on\n",
    "implicit positive feedback (ratings ≥ 4 vs. unobserved items). This directly\n",
    "optimizes ranking quality instead of absolute rating accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos = train[train['rating'] >= 4]\n",
    "train_pos['u_idx'] = train_pos['user_id'].map(user_map)\n",
    "train_pos['i_idx'] = train_pos['movie_id'].map(item_map)\n",
    "train_pos = train_pos.dropna(subset=['u_idx', 'i_idx'])\n",
    "\n",
    "user_pos_items = train_pos.groupby('u_idx')['i_idx'].apply(lambda x: list(set(x))).to_dict()\n",
    "\n",
    "\n",
    "class BPRTripletDataset(Dataset):\n",
    "    def __init__(self, n_items: int, user_pos_items: dict[int, list[int]], n_samples: int = 1):\n",
    "        self.n_items = n_items\n",
    "        self.user_pos_items = user_pos_items\n",
    "        self.users = list(user_pos_items.keys())\n",
    "        self.n_samples = n_samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum(len(items) for items in self.user_pos_items.values()) * self.n_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        u = np.random.choice(self.users)\n",
    "        pos_items = self.user_pos_items[u]\n",
    "        i = np.random.choice(pos_items)\n",
    "\n",
    "        j = np.random.randint(0, self.n_items)\n",
    "        while j in pos_items:\n",
    "            j = np.random.randint(0, self.n_items)\n",
    "\n",
    "        return (\n",
    "            torch.tensor(u, dtype=torch.long),\n",
    "            torch.tensor(i, dtype=torch.long),\n",
    "            torch.tensor(j, dtype=torch.long),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - BPR loss: 0.6896\n",
      "Epoch 2/5 - BPR loss: 0.5691\n",
      "Epoch 3/5 - BPR loss: 0.3619\n",
      "Epoch 4/5 - BPR loss: 0.2907\n",
      "Epoch 5/5 - BPR loss: 0.2699\n"
     ]
    }
   ],
   "source": [
    "bpr_batch_size = 4096\n",
    "bpr_lr = 1e-3\n",
    "bpr_epochs = 5\n",
    "\n",
    "bpr_ds = BPRTripletDataset(n_items=n_items, user_pos_items=user_pos_items, n_samples=1)\n",
    "bpr_loader = DataLoader(bpr_ds, batch_size=bpr_batch_size, shuffle=True)\n",
    "\n",
    "model_bpr = TwoTowerBPR(n_users=n_users, n_items=n_items, embed_dim=32, l2_reg=1e-4).to(device)\n",
    "optimizer_bpr = torch.optim.Adam(model_bpr.parameters(), lr=bpr_lr)\n",
    "\n",
    "for epoch in range(1, bpr_epochs + 1):\n",
    "    model_bpr.train()\n",
    "    total_loss = 0.0\n",
    "    for u, i, j in bpr_loader:\n",
    "        u = u.to(device)\n",
    "        i = i.to(device)\n",
    "        j = j.to(device)\n",
    "\n",
    "        optimizer_bpr.zero_grad()\n",
    "        loss = model_bpr.bpr_loss(u, i, j)\n",
    "        loss.backward()\n",
    "        optimizer_bpr.step()\n",
    "\n",
    "        total_loss += loss.item() * len(u)\n",
    "\n",
    "    avg_loss = total_loss / len(bpr_ds)\n",
    "    print(f\"Epoch {epoch}/{bpr_epochs} - BPR loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TwoTowerBPR - Precision@10: 0.1847\n",
      "TwoTowerBPR - Recall@10:    0.0540\n",
      "TwoTowerBPR - NDCG@10:      0.2428\n"
     ]
    }
   ],
   "source": [
    "model_bpr.eval()\n",
    "\n",
    "train_user_items_idx = train.groupby('user_id')['movie_id'].apply(\n",
    "    lambda items: [item_map[m] for m in items if m in item_map]\n",
    ").to_dict()\n",
    "\n",
    "candidate_item_indices = torch.arange(n_items, dtype=torch.long, device=device)\n",
    "\n",
    "def bpr_recommend_k(\n",
    "    user_id: int,\n",
    "    k: int,\n",
    "    model,\n",
    "    user_map,\n",
    "    item_map,\n",
    "    test: pd.DataFrame | None = None,\n",
    ") -> np.ndarray:\n",
    "    if user_id not in user_map:\n",
    "        return np.array([], dtype=int)\n",
    "\n",
    "    u_idx = user_map[user_id]\n",
    "\n",
    "    if test is not None:\n",
    "        test_items = test['movie_id'].unique()\n",
    "    else:\n",
    "        test_items = list(item_map.keys())\n",
    "        \n",
    "    test_items_idx = [item_map[m] for m in test_items if m in item_map]\n",
    "    if not test_items_idx:\n",
    "        return np.array([], dtype=int)\n",
    "\n",
    "    test_items_idx = torch.tensor(test_items_idx, dtype=torch.long, device=device)\n",
    "\n",
    "    seen_items_idx = set(train_user_items_idx.get(user_id, []))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        topk_indices = model.recommend_for_user(\n",
    "            user_index=u_idx,\n",
    "            candidate_item_indices=test_items_idx,\n",
    "            seen_item_indices=seen_items_idx,\n",
    "            k=k,\n",
    "        )\n",
    "\n",
    "    inv_item_map = {v: k for k, v in item_map.items()}\n",
    "    topk_indices_cpu = topk_indices.cpu().numpy().tolist()\n",
    "    rec_movie_ids = [inv_item_map[idx] for idx in topk_indices_cpu if idx in inv_item_map]\n",
    "    return np.array(rec_movie_ids, dtype=int)\n",
    "\n",
    "\n",
    "prec_bpr = evaluate_precision_at_k(test, bpr_recommend_k, k=10, model=model_bpr, user_map=user_map, item_map=item_map)\n",
    "recall_bpr = evaluate_recall_at_k(test, bpr_recommend_k, k=10, model=model_bpr, user_map=user_map, item_map=item_map)\n",
    "ndcg_bpr = evaluate_ndcg_at_k(test, bpr_recommend_k, k=10, model=model_bpr, user_map=user_map, item_map=item_map)\n",
    "\n",
    "print(f\"TwoTowerBPR - Precision@10: {prec_bpr:.4f}\")\n",
    "print(f\"TwoTowerBPR - Recall@10:    {recall_bpr:.4f}\")\n",
    "print(f\"TwoTowerBPR - NDCG@10:      {ndcg_bpr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Critical discussion\n",
    "\n",
    "### Representational differences vs MF/BPR\n",
    "- **NeuralMF vs SVD/ALS (MF)**: MF uses a single dot product between user and item factors, which assumes a linear interaction in the shared latent space. NeuralMF replaces this with an MLP over concatenated embeddings, allowing non-linear feature interactions and user–item specific effects (e.g., saturation, cross-features). This can capture more complex patterns (e.g., genre combinations or user taste shifts) at the cost of higher capacity and risk of overfitting.\n",
    "- **TwoTowerBPR vs classical BPR-Opt**: Both optimize a pairwise ranking objective, but classical BPR-Opt uses a purely linear score (dot product of latent factors learned via SGD in NumPy), while TwoTowerBPR is implemented as a neural two-tower model in PyTorch. Architecturally they are very similar (embeddings + dot product); the key difference is the training framework, which makes it easy to extend TwoTowerBPR with deeper towers or side features if needed.\n",
    "\n",
    "### Optimization and compute trade-offs\n",
    "- **Classical MF (SVD/ALS)** solves a (roughly) convex problem with efficient closed-form updates (ALS) or simple SGD on a small number of parameters, which tends to converge quickly and is stable. NeuralMF introduces many more parameters and non-linearities; optimization is fully first-order (Adam) and can be slower and more sensitive to hyperparameters. It also requires batching and careful regularization.\n",
    "- **BPR-Opt vs TwoTowerBPR**: Both rely on negative sampling and SGD over triplets. The NumPy BPR-Opt implementation is lightweight and CPU-friendly; the PyTorch TwoTowerBPR can leverage GPUs and batched operations, but its per-step overhead is higher. In practice, if we keep the embedding dimension small, the compute cost remains manageable, but the neural version becomes more appealing when we want to scale to larger models or add complex features.\n",
    "\n",
    "### Why performance improves or degrades\n",
    "- On rating prediction (RMSE/MAE), **NeuralMF** may slightly improve over MF if the data truly contains non-linear interaction patterns and we tune the model carefully. On smaller or noisy datasets, the extra capacity can hurt, leading to similar or worse RMSE than a well-regularized MF baseline, while requiring more compute.\n",
    "- On ranking metrics (Precision@K/Recall@K/NDCG@K), **TwoTowerBPR** is often more competitive because its objective is directly aligned with ranking. Compared to classical BPR-Opt, we expect similar behaviour when using the same embedding size; any gains usually come from better regularization and the ability to scale up or extend the architecture, not from “depth” alone.\n",
    "- Overall, the experiments here illustrate that **neural recommenders are not automatically better**: they trade analytical simplicity and fast convergence (MF/BPR) for additional representational power. Whether this pays off depends on data scale, noise level, and how well we tune the models. In small-to-medium regimes like MovieLens 1M, modest non-linear models tend to be competitive but not dramatically better than strong MF/BPR baselines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
