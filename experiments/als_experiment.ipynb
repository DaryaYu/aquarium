{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# ALS (Alternating Least Squares) Experiment\n",
    "\n",
    "This notebook tests and validates the ALS implementation for implicit feedback collaborative filtering.\n",
    "\n",
    "## Theory\n",
    "\n",
    "ALS decomposes the user-item matrix into two matrices:\n",
    "$$R \\approx U \\cdot V^T$$\n",
    "\n",
    "Where:\n",
    "- $U$ is the user feature matrix (m × f)\n",
    "- $V$ is the item feature matrix (n × f)\n",
    "- f is the number of latent factors\n",
    "\n",
    "For implicit feedback:\n",
    "- **Preference**: $p_{ui} = 1$ if $r_{ui} > 0$, else $0$\n",
    "- **Confidence**: $c_{ui} = 1 + \\alpha \\cdot r_{ui}$\n",
    "\n",
    "The algorithm alternates between:\n",
    "1. Fixing $V$ and solving for $U$\n",
    "2. Fixing $U$ and solving for $V$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "sys.path.append(str(PROJECT_ROOT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from src.data_reading import read_ratings_file\n",
    "from src.evaluation import temporal_split, evaluate_rmse\n",
    "from src.models.als import solve_with_als\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load_data_header",
   "metadata": {},
   "source": [
    "## Load and Split Data\n",
    "\n",
    "Using temporal split to ensure realistic evaluation (train on past, test on future)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "load_data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1000209 ratings\n",
      "Train set size is: (800168, 4) \n",
      "Test set size is: (200041, 4)\n",
      "Train set timeframes are: 2000-04-25 23:05:32 - 2000-12-02 14:52:18 \n",
      "Test set timeframes are 2000-12-02 14:52:28 - 2003-02-28 17:49:50\n"
     ]
    }
   ],
   "source": [
    "ratings = read_ratings_file()\n",
    "print(f\"Loaded {len(ratings)} ratings\")\n",
    "\n",
    "# Temporal split: train on past, test on future\n",
    "train, test = temporal_split(ratings, test_ratio=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "create_matrix_header",
   "metadata": {},
   "source": [
    "## Create Ratings Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "create_matrix",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training matrix shape: (5400, 3662)\n",
      "Sparsity: 95.95%\n",
      "\n",
      "Filtered test set size: 104448 ratings\n"
     ]
    }
   ],
   "source": [
    "train_matrix = train.pivot_table(\n",
    "    index='user_id',\n",
    "    columns='movie_id',\n",
    "    values='rating',\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "print(f\"Training matrix shape: {train_matrix.shape}\")\n",
    "print(f\"Sparsity: {(train_matrix == 0).sum().sum() / (train_matrix.shape[0] * train_matrix.shape[1]) * 100:.2f}%\")\n",
    "\n",
    "# Filter test set to only include users/movies in training set (no cold start)\n",
    "test_users = np.intersect1d(test.user_id.unique(), train.user_id.unique())\n",
    "test_movies = np.intersect1d(test.movie_id.unique(), train.movie_id.unique())\n",
    "test = test[(test.user_id.isin(test_users)) & (test.movie_id.isin(test_movies))]\n",
    "print(f\"\\nFiltered test set size: {test.shape[0]} ratings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "train_header",
   "metadata": {},
   "source": [
    "## Train ALS Model\n",
    "\n",
    "We'll test different hyperparameter configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "train_default",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ALS with default parameters...\n",
      "--- Running ALS with parameters ---\n",
      "Alpha: 40\n",
      "Iterations: 10\n",
      "Factors: 20\n",
      "Regularization: 0.1\n",
      "\n",
      "Iteration 1/10\n",
      "Solving for users (fixed items)...\n",
      "Solving for items (fixed users)...\n",
      "\n",
      "Iteration 2/10\n",
      "Solving for users (fixed items)...\n",
      "Solving for items (fixed users)...\n",
      "\n",
      "Iteration 3/10\n",
      "Solving for users (fixed items)...\n",
      "Solving for items (fixed users)...\n",
      "\n",
      "Iteration 4/10\n",
      "Solving for users (fixed items)...\n",
      "Solving for items (fixed users)...\n",
      "\n",
      "Iteration 5/10\n",
      "Solving for users (fixed items)...\n",
      "Solving for items (fixed users)...\n",
      "\n",
      "Iteration 6/10\n",
      "Solving for users (fixed items)...\n",
      "Solving for items (fixed users)...\n",
      "\n",
      "Iteration 7/10\n",
      "Solving for users (fixed items)...\n",
      "Solving for items (fixed users)...\n",
      "\n",
      "Iteration 8/10\n",
      "Solving for users (fixed items)...\n",
      "Solving for items (fixed users)...\n",
      "\n",
      "Iteration 9/10\n",
      "Solving for users (fixed items)...\n",
      "Solving for items (fixed users)...\n",
      "\n",
      "Iteration 10/10\n",
      "Solving for users (fixed items)...\n",
      "Solving for items (fixed users)...\n",
      "\n",
      "✓ Default model trained\n"
     ]
    }
   ],
   "source": [
    "# Train with default parameters first\n",
    "print(\"Training ALS with default parameters...\")\n",
    "default_predictions = solve_with_als(\n",
    "    train_matrix,\n",
    "    alpha=40,\n",
    "    iterations=10,\n",
    "    factors=20,\n",
    "    regularization=0.1,\n",
    "    verbose=True\n",
    ")\n",
    "print(\"\\n✓ Default model trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eval_header",
   "metadata": {},
   "source": [
    "## Evaluate Default Model\n",
    "\n",
    "Using RMSE evaluation consistent with other experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2ad930-d320-4368-bfb5-095194967b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(user_id, movie_id):\n",
    "    try:\n",
    "        return prediction_matrix.loc[user_id, movie_id]\n",
    "    except (KeyError, IndexError):\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "evaluate_default",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default model RMSE: 3.0631\n"
     ]
    }
   ],
   "source": [
    "predict_fn = create_predict_fn(default_predictions)\n",
    "default_rmse = evaluate_rmse(test=test, predict_fn=predict)\n",
    "\n",
    "print(f\"Default model RMSE: {default_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "param_tuning_header",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "### Test Different Number of Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "test_factors",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with factors=10...\n",
      "--- Running ALS with parameters ---\n",
      "Alpha: 40\n",
      "Iterations: 10\n",
      "Factors: 10\n",
      "Regularization: 0.1\n",
      "\n",
      "Iteration 1/10\n",
      "Solving for users (fixed items)...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m factors \u001b[38;5;129;01min\u001b[39;00m factor_values:\n\u001b[32m      6\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTraining with factors=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfactors\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     predictions = \u001b[43msolve_with_als\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_matrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m40\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43miterations\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfactors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfactors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[43mregularization\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m     predict_fn = create_predict_fn(predictions)\n\u001b[32m     17\u001b[39m     rmse = evaluate_rmse(test=test, predict_fn=predict_fn)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/app/src/models/als.py:127\u001b[39m, in \u001b[36msolve_with_als\u001b[39m\u001b[34m(ratings_matrix, alpha, iterations, factors, regularization, random_seed, verbose)\u001b[39m\n\u001b[32m    124\u001b[39m itemTCuIitem = item_matrix.T.dot(CuI).dot(item_matrix)\n\u001b[32m    126\u001b[39m \u001b[38;5;66;03m# Compute Y^T C_u p(u)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m itemTCuPu = \u001b[43mitem_matrix\u001b[49m\u001b[43m.\u001b[49m\u001b[43mT\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCuI\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_eye\u001b[49m\u001b[43m)\u001b[49m.dot(preference_vector.T)\n\u001b[32m    129\u001b[39m \u001b[38;5;66;03m# Solve: x_u = (Y^T Y + Y^T(C_u - I)Y + λI)^(-1) Y^T C_u p(u)\u001b[39;00m\n\u001b[32m    130\u001b[39m user_matrix[user] = spsolve(\n\u001b[32m    131\u001b[39m     itemTitem + itemTCuIitem + lambda_eye, itemTCuPu\n\u001b[32m    132\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/scipy/sparse/_base.py:603\u001b[39m, in \u001b[36m_spbase.dot\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m    601\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m * other\n\u001b[32m    602\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m603\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m@\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/scipy/sparse/_base.py:923\u001b[39m, in \u001b[36m_spbase.__matmul__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isscalarlike(other):\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mScalar operands are not allowed, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    922\u001b[39m                      \u001b[33m\"\u001b[39m\u001b[33muse \u001b[39m\u001b[33m'\u001b[39m\u001b[33m*\u001b[39m\u001b[33m'\u001b[39m\u001b[33m instead\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m923\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_matmul_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/scipy/sparse/_base.py:827\u001b[39m, in \u001b[36m_spbase._matmul_dispatch\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m    823\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m N != other.shape[\u001b[32m0\u001b[39m]:\n\u001b[32m    824\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    825\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (n,k=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mN\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m),(k=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mother.shape[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m,m)->(n,m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    826\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m827\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_matmul_sparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    829\u001b[39m \u001b[38;5;66;03m# If it's a list or whatever, treat it like an array\u001b[39;00m\n\u001b[32m    830\u001b[39m other_a = np.asanyarray(other)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/scipy/sparse/_compressed.py:462\u001b[39m, in \u001b[36m_cs_matrix._matmul_sparse\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m    459\u001b[39m indices = np.empty(nnz, dtype=idx_dtype)\n\u001b[32m    460\u001b[39m data = np.empty(nnz, dtype=upcast(\u001b[38;5;28mself\u001b[39m.dtype, other.dtype))\n\u001b[32m--> \u001b[39m\u001b[32m462\u001b[39m \u001b[43mcsr_matmat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m           \u001b[49m\u001b[43ms_indptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    464\u001b[39m \u001b[43m           \u001b[49m\u001b[43mo_indptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mo_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[43m           \u001b[49m\u001b[43mindptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m new_shape == ():\n\u001b[32m    468\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.array(data[\u001b[32m0\u001b[39m])\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Test different number of factors\n",
    "factor_values = [10, 20, 50]\n",
    "factor_results = []\n",
    "\n",
    "for factors in factor_values:\n",
    "    print(f\"\\nTraining with factors={factors}...\")\n",
    "    predictions = solve_with_als(\n",
    "        train_matrix,\n",
    "        alpha=40,\n",
    "        iterations=10,\n",
    "        factors=factors,\n",
    "        regularization=0.1,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    predict_fn = create_predict_fn(predictions)\n",
    "    rmse = evaluate_rmse(test=test, predict_fn=predict_fn)\n",
    "    \n",
    "    factor_results.append({\n",
    "        'factors': factors,\n",
    "        'RMSE': rmse\n",
    "    })\n",
    "    print(f\"  RMSE: {rmse:.4f}\")\n",
    "\n",
    "factor_df = pd.DataFrame(factor_results)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ALS: Number of Factors\")\n",
    "print(\"=\"*60)\n",
    "print(factor_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test_alpha_header",
   "metadata": {},
   "source": [
    "### Test Different Alpha Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_alpha",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different alpha values\n",
    "alpha_values = [10, 40, 80]\n",
    "alpha_results = []\n",
    "\n",
    "for alpha in alpha_values:\n",
    "    print(f\"\\nTraining with alpha={alpha}...\")\n",
    "    predictions = solve_with_als(\n",
    "        train_matrix,\n",
    "        alpha=alpha,\n",
    "        iterations=10,\n",
    "        factors=20,\n",
    "        regularization=0.1,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    predict_fn = create_predict_fn(predictions)\n",
    "    rmse = evaluate_rmse(test=test, predict_fn=predict_fn)\n",
    "    \n",
    "    alpha_results.append({\n",
    "        'alpha': alpha,\n",
    "        'RMSE': rmse\n",
    "    })\n",
    "    print(f\"  RMSE: {rmse:.4f}\")\n",
    "\n",
    "alpha_df = pd.DataFrame(alpha_results)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ALS: Alpha Parameter\")\n",
    "print(\"=\"*60)\n",
    "print(alpha_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test_iterations_header",
   "metadata": {},
   "source": [
    "### Test Different Iteration Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_iterations",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different iteration counts\n",
    "iteration_values = [5, 10, 15]\n",
    "iteration_results = []\n",
    "\n",
    "for iters in iteration_values:\n",
    "    print(f\"\\nTraining with iterations={iters}...\")\n",
    "    predictions = solve_with_als(\n",
    "        train_matrix,\n",
    "        alpha=40,\n",
    "        iterations=iters,\n",
    "        factors=20,\n",
    "        regularization=0.1,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    predict_fn = create_predict_fn(predictions)\n",
    "    rmse = evaluate_rmse(test=test, predict_fn=predict_fn)\n",
    "    \n",
    "    iteration_results.append({\n",
    "        'iterations': iters,\n",
    "        'RMSE': rmse\n",
    "    })\n",
    "    print(f\"  RMSE: {rmse:.4f}\")\n",
    "\n",
    "iteration_df = pd.DataFrame(iteration_results)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ALS: Number of Iterations\")\n",
    "print(\"=\"*60)\n",
    "print(iteration_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viz_header",
   "metadata": {},
   "source": [
    "## Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Factors plot\n",
    "axes[0].plot(factor_df['factors'], factor_df['RMSE'], marker='o', linewidth=2, markersize=8)\n",
    "axes[0].set_xlabel('Number of Latent Factors', fontsize=12)\n",
    "axes[0].set_ylabel('RMSE', fontsize=12)\n",
    "axes[0].set_title('ALS: Factors Sensitivity', fontsize=14)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Alpha plot\n",
    "axes[1].plot(alpha_df['alpha'], alpha_df['RMSE'], marker='o', linewidth=2, markersize=8)\n",
    "axes[1].set_xlabel('Alpha (Confidence Scaling)', fontsize=12)\n",
    "axes[1].set_ylabel('RMSE', fontsize=12)\n",
    "axes[1].set_title('ALS: Alpha Sensitivity', fontsize=14)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Iterations plot\n",
    "axes[2].plot(iteration_df['iterations'], iteration_df['RMSE'], marker='o', linewidth=2, markersize=8)\n",
    "axes[2].set_xlabel('Number of Iterations', fontsize=12)\n",
    "axes[2].set_ylabel('RMSE', fontsize=12)\n",
    "axes[2].set_title('ALS: Convergence', fontsize=14)\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "best_model_header",
   "metadata": {},
   "source": [
    "## Summary of Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "best_params",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best values\n",
    "best_factors = factor_df.loc[factor_df['RMSE'].idxmin(), 'factors']\n",
    "best_alpha = alpha_df.loc[alpha_df['RMSE'].idxmin(), 'alpha']\n",
    "best_iterations = iteration_df.loc[iteration_df['RMSE'].idxmin(), 'iterations']\n",
    "\n",
    "print(\"Best Parameters:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Factors: {int(best_factors)} (RMSE: {factor_df['RMSE'].min():.4f})\")\n",
    "print(f\"Alpha: {int(best_alpha)} (RMSE: {alpha_df['RMSE'].min():.4f})\")\n",
    "print(f\"Iterations: {int(best_iterations)} (RMSE: {iteration_df['RMSE'].min():.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analysis_header",
   "metadata": {},
   "source": [
    "## Detailed Analysis of Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train_best",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with best parameters\n",
    "print(\"Training ALS with best parameters...\")\n",
    "best_predictions = solve_with_als(\n",
    "    train_matrix,\n",
    "    alpha=int(best_alpha),\n",
    "    iterations=int(best_iterations),\n",
    "    factors=int(best_factors),\n",
    "    regularization=0.1,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "predict_fn = create_predict_fn(best_predictions)\n",
    "best_rmse = evaluate_rmse(test=test, predict_fn=predict_fn)\n",
    "print(f\"\\nBest model RMSE: {best_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze prediction distribution\n",
    "print(f\"\\nPrediction statistics:\")\n",
    "print(f\"  Min: {best_predictions.min().min():.2f}\")\n",
    "print(f\"  Max: {best_predictions.max().max():.2f}\")\n",
    "print(f\"  Mean: {best_predictions.mean().mean():.2f}\")\n",
    "print(f\"  Std: {best_predictions.std().std():.2f}\")\n",
    "\n",
    "# Compare with actual ratings\n",
    "print(f\"\\nActual ratings statistics:\")\n",
    "print(f\"  Min: {train_matrix[train_matrix > 0].min().min():.2f}\")\n",
    "print(f\"  Max: {train_matrix.max().max():.2f}\")\n",
    "print(f\"  Mean: {train_matrix[train_matrix > 0].mean().mean():.2f}\")\n",
    "print(f\"  Std: {train_matrix[train_matrix > 0].std().std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sample_predictions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample predictions for a random user\n",
    "sample_user = np.random.choice(train_matrix.index)\n",
    "user_actual = train_matrix.loc[sample_user]\n",
    "user_pred = best_predictions.loc[sample_user]\n",
    "\n",
    "# Get rated movies\n",
    "rated_movies = user_actual[user_actual > 0].sample(min(10, (user_actual > 0).sum()))\n",
    "comparison = pd.DataFrame({\n",
    "    'Actual': rated_movies,\n",
    "    'Predicted': user_pred[rated_movies.index]\n",
    "})\n",
    "\n",
    "print(f\"Sample predictions for User {sample_user}:\")\n",
    "print(comparison)\n",
    "\n",
    "# Calculate correlation\n",
    "corr = comparison['Actual'].corr(comparison['Predicted'])\n",
    "print(f\"\\nCorrelation: {corr:.4f}\")\n",
    "\n",
    "# Show top recommendations (unrated movies)\n",
    "unrated_movies = user_actual[user_actual == 0]\n",
    "top_recs = user_pred[unrated_movies.index].nlargest(5)\n",
    "print(f\"\\nTop 5 recommendations for User {sample_user}:\")\n",
    "for movie_id, score in top_recs.items():\n",
    "    print(f\"  Movie {movie_id}: {score:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
