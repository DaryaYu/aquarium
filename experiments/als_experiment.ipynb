{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# ALS (Alternating Least Squares) Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "sys.path.append(str(PROJECT_ROOT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from src.data_reading import read_ratings_file\n",
    "from src.evaluation import temporal_split, evaluate_rmse, evaluate_mape, evaluate_precision_at_k\n",
    "from src.models.als import solve_with_als\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load_data_header",
   "metadata": {},
   "source": [
    "## Load and Split Data\n",
    "\n",
    "Using temporal split to ensure realistic evaluation (train on past, test on future)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "load_data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1000209 ratings\n",
      "Train set size: (700148, 4)\n",
      "Validation set size: (100020, 4)\n",
      "Test set size: (200041, 4)\n",
      "Train timeframe: 2000-04-25 23:05:32 - 2000-11-22 03:06:26\n",
      "Val timeframe: 2000-11-22 03:06:30 - 2000-12-02 14:52:18\n",
      "Test timeframe: 2000-12-02 14:52:28 - 2003-02-28 17:49:50\n"
     ]
    }
   ],
   "source": [
    "ratings = read_ratings_file()\n",
    "print(f\"Loaded {len(ratings)} ratings\")\n",
    "\n",
    "# Temporal split: train on past, validate on middle, test on future\n",
    "train, val, test = temporal_split(ratings, test_ratio=0.2, val_ratio=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "create_matrix_header",
   "metadata": {},
   "source": [
    "## Create Ratings Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "create_matrix",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training matrix shape: (4870, 3633)\n",
      "Sparsity: 96.04%\n",
      "\n",
      "Filtered validation set size: 26246 ratings\n",
      "Filtered test set size: 84804 ratings\n"
     ]
    }
   ],
   "source": [
    "train_matrix = train.pivot_table(\n",
    "    index='user_id',\n",
    "    columns='movie_id',\n",
    "    values='rating',\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "print(f\"Training matrix shape: {train_matrix.shape}\")\n",
    "print(f\"Sparsity: {(train_matrix == 0).sum().sum() / (train_matrix.shape[0] * train_matrix.shape[1]) * 100:.2f}%\")\n",
    "\n",
    "# Filter validation and test sets to only include users/movies in training set (no cold start)\n",
    "train_users = train.user_id.unique()\n",
    "train_movies = train.movie_id.unique()\n",
    "\n",
    "val = val[(val.user_id.isin(train_users)) & (val.movie_id.isin(train_movies))]\n",
    "test = test[(test.user_id.isin(train_users)) & (test.movie_id.isin(train_movies))]\n",
    "\n",
    "print(f\"\\nFiltered validation set size: {val.shape[0]} ratings\")\n",
    "print(f\"Filtered test set size: {test.shape[0]} ratings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "train_header",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "We'll train models with different hyperparameter combinations and select the best based on validation set performance.\n",
    "\n",
    "**Hyperparameters to tune:**\n",
    "- **factors**: Number of latent factors\n",
    "- **alpha**: Confidence scaling parameter for implicit feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "train_default",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: factors=10, alpha=20\n",
      "  Validation RMSE: 3.6193\n",
      "\n",
      "Training: factors=10, alpha=60\n",
      "  Validation RMSE: 3.5392\n",
      "\n",
      "Training: factors=40, alpha=20\n",
      "  Validation RMSE: 3.5752\n",
      "\n",
      "Training: factors=40, alpha=60\n",
      "  Validation RMSE: 3.4497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'factors': [10, 40],\n",
    "    'alpha': [20, 60],\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for factors in param_grid['factors']:\n",
    "    for alpha in param_grid['alpha']:\n",
    "        print(f\"Training: factors={factors}, alpha={alpha}\")\n",
    "        \n",
    "        predictions = solve_with_als(\n",
    "            train_matrix,\n",
    "            alpha=alpha,\n",
    "            iterations=1,\n",
    "            factors=factors,\n",
    "            regularization=0.1,\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        def predict(user_id, movie_id, pred_matrix=predictions):\n",
    "            try:\n",
    "                return pred_matrix.loc[user_id, movie_id]\n",
    "            except (KeyError, IndexError):\n",
    "                return np.nan\n",
    "        \n",
    "        val_rmse = evaluate_rmse(test=val, predict_fn=predict)\n",
    "        \n",
    "        results.append({\n",
    "            'factors': factors,\n",
    "            'alpha': alpha,\n",
    "            'regularization': 0.1,\n",
    "            'val_rmse': val_rmse,\n",
    "        })\n",
    "        \n",
    "        print(f\"  Validation RMSE: {val_rmse:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eval_header",
   "metadata": {},
   "source": [
    "## Select Best Model\n",
    "\n",
    "Find the hyperparameters with lowest validation RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "evaluate_default",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best hyperparameters:\n",
      "  factors=40, alpha=60.0\n",
      "  Validation RMSE: 3.4497\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame([{k: v for k, v in r.items() if k != 'predictions'} for r in results])\n",
    "results_df = results_df.sort_values('val_rmse')\n",
    "\n",
    "best_config = results_df.iloc[0]\n",
    "best_params = {\n",
    "    'factors': int(best_config['factors']),\n",
    "    'alpha': float(best_config['alpha']),\n",
    "}\n",
    "\n",
    "print(f\"\\nBest hyperparameters:\")\n",
    "print(f\"  factors={best_params['factors']}, alpha={best_params['alpha']}\")\n",
    "print(f\"  Validation RMSE: {best_config['val_rmse']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2ad930-d320-4368-bfb5-095194967b0b",
   "metadata": {},
   "source": [
    "## Retrain Best Model\n",
    "\n",
    "Retrain with best hyperparameters using more iterations for better convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5036m1snjs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 1/15\n",
      "Solving for users (fixed items)...\n",
      "Solving for items (fixed users)...\n",
      "\n",
      "Iteration 2/15\n",
      "Solving for users (fixed items)...\n",
      "Solving for items (fixed users)...\n",
      "\n",
      "Iteration 3/15\n",
      "Solving for users (fixed items)...\n",
      "Solving for items (fixed users)...\n",
      "\n",
      "Iteration 4/15\n",
      "Solving for users (fixed items)...\n",
      "Solving for items (fixed users)...\n",
      "\n",
      "Iteration 5/15\n",
      "Solving for users (fixed items)...\n",
      "Solving for items (fixed users)...\n",
      "\n",
      "Iteration 6/15\n",
      "Solving for users (fixed items)...\n",
      "Solving for items (fixed users)...\n",
      "\n",
      "Iteration 7/15\n",
      "Solving for users (fixed items)...\n",
      "Solving for items (fixed users)...\n",
      "\n",
      "Iteration 8/15\n",
      "Solving for users (fixed items)...\n",
      "Solving for items (fixed users)...\n",
      "\n",
      "Iteration 9/15\n",
      "Solving for users (fixed items)...\n",
      "Solving for items (fixed users)...\n",
      "\n",
      "Iteration 10/15\n",
      "Solving for users (fixed items)...\n",
      "Solving for items (fixed users)...\n",
      "\n",
      "Iteration 11/15\n",
      "Solving for users (fixed items)...\n",
      "Solving for items (fixed users)...\n",
      "\n",
      "Iteration 12/15\n",
      "Solving for users (fixed items)...\n",
      "Solving for items (fixed users)...\n",
      "\n",
      "Iteration 13/15\n",
      "Solving for users (fixed items)...\n",
      "Solving for items (fixed users)...\n",
      "\n",
      "Iteration 14/15\n",
      "Solving for users (fixed items)...\n",
      "Solving for items (fixed users)...\n",
      "\n",
      "Iteration 15/15\n",
      "Solving for users (fixed items)...\n",
      "Solving for items (fixed users)...\n"
     ]
    }
   ],
   "source": [
    "final_predictions = solve_with_als(\n",
    "    train_matrix,\n",
    "    alpha=best_60,\n",
    "    iterations=15, \n",
    "    factors=best_rams['factors'],\n",
    "    regularization=0.1,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rcgh8wqxkfc",
   "metadata": {},
   "source": [
    "## Final Test Evaluation\n",
    "\n",
    "Evaluate the best model on the held-out test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "czsoi6dsm4l",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 3.1120\n",
      "MAPE: 81.38%\n",
      "\n",
      "Precision@5: 0.0684\n",
      "\n",
      "Precision@10: 0.0619\n",
      "\n",
      "Precision@20: 0.0588\n",
      "\n",
      "==================================================\n",
      "Best hyperparameters: factors=40, alpha=60\n"
     ]
    }
   ],
   "source": [
    "def predict_final(user_id, movie_id):\n",
    "    try:\n",
    "        return final_predictions.loc[user_id, movie_id]\n",
    "    except (KeyError, IndexError):\n",
    "        return np.nan\n",
    "\n",
    "def recommend_k(user_id, test, k, **kwargs):\n",
    "    try:\n",
    "        user_preds = final_predictions.loc[user_id]\n",
    "        return user_preds.nlargest(k).index.values\n",
    "    except (KeyError, IndexError):\n",
    "        return np.array([])\n",
    "\n",
    "\n",
    "test_rmse = evaluate_rmse(test=test, predict_fn=predict_final)\n",
    "print(f\"RMSE: {test_rmse:.4f}\")\n",
    "\n",
    "test_mape = evaluate_mape(test=test, predict_fn=predict_final)\n",
    "print(f\"MAPE: {test_mape:.2f}%\")\n",
    "\n",
    "for k in [5, 10, 20]:\n",
    "    precision_k = evaluate_precision_at_k(test=test, recommend_k_fn=recommend_k, k=k)\n",
    "    print(f\"\\nPrecision@{k}: {precision_k:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(f\"Best hyperparameters: factors={best_params['factors']}, alpha={best_params['alpha']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dec635-3ebb-485e-815e-0830dc53044c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
