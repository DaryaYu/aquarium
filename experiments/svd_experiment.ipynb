{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# SVD (Singular Value Decomposition) Experiment\n",
    "\n",
    "This notebook tests and validates the SVD implementation for collaborative filtering.\n",
    "\n",
    "## Theory\n",
    "\n",
    "SVD decomposes a matrix R into three matrices:\n",
    "$$R \\approx U \\Sigma V^T$$\n",
    "\n",
    "Where:\n",
    "- $U$ is the user feature matrix (m × k)\n",
    "- $\\Sigma$ is the diagonal matrix of singular values (k × k)\n",
    "- $V^T$ is the item feature matrix transposed (k × n)\n",
    "- k is the number of latent factors\n",
    "\n",
    "By keeping only the top k singular values, we get a low-rank approximation that captures the most important patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "sys.path.append(str(PROJECT_ROOT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from src.data_reading import read_ratings_file\n",
    "from src.evaluation import temporal_split, evaluate_rmse\n",
    "from src.models.svd import solve_with_svd\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load_data_header",
   "metadata": {},
   "source": [
    "## Load and Split Data\n",
    "\n",
    "Using temporal split to ensure realistic evaluation (train on past, test on future)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "load_data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1000209 ratings\n",
      "Train set size is: (800168, 4) \n",
      "Test set size is: (200041, 4)\n",
      "Train set timeframes are: 2000-04-25 23:05:32 - 2000-12-02 14:52:18 \n",
      "Test set timeframes are 2000-12-02 14:52:28 - 2003-02-28 17:49:50\n"
     ]
    }
   ],
   "source": [
    "ratings = read_ratings_file()\n",
    "print(f\"Loaded {len(ratings)} ratings\")\n",
    "\n",
    "# Temporal split: train on past, test on future\n",
    "train, test = temporal_split(ratings, test_ratio=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "create_matrix_header",
   "metadata": {},
   "source": [
    "## Create Ratings Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "create_matrix",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training matrix shape: (5400, 3662)\n",
      "Sparsity: 95.95%\n",
      "\n",
      "Filtered test set size: 104448 ratings\n"
     ]
    }
   ],
   "source": [
    "train_matrix = train.pivot_table(\n",
    "    index='user_id',\n",
    "    columns='movie_id',\n",
    "    values='rating',\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "print(f\"Training matrix shape: {train_matrix.shape}\")\n",
    "print(f\"Sparsity: {(train_matrix == 0).sum().sum() / (train_matrix.shape[0] * train_matrix.shape[1]) * 100:.2f}%\")\n",
    "\n",
    "# Filter test set to only include users/movies in training set (no cold start)\n",
    "test_users = np.intersect1d(test.user_id.unique(), train.user_id.unique())\n",
    "test_movies = np.intersect1d(test.movie_id.unique(), train.movie_id.unique())\n",
    "test = test[(test.user_id.isin(test_users)) & (test.movie_id.isin(test_movies))]\n",
    "print(f\"\\nFiltered test set size: {test.shape[0]} ratings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "train_header",
   "metadata": {},
   "source": [
    "## Train SVD Model\n",
    "\n",
    "We'll test different values of k (number of latent factors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train_models",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVD with k=10...\n"
     ]
    }
   ],
   "source": [
    "# Train models with different k values\n",
    "# k_values = [10, 20, 50, 100]\n",
    "k_values = [10]\n",
    "models = {}\n",
    "\n",
    "for k in k_values:\n",
    "    print(f\"Training SVD with k={k}...\")\n",
    "    predictions = solve_with_svd(train_matrix, k=k)\n",
    "    models[k] = predictions\n",
    "    print(f\"  Completed.\")\n",
    "\n",
    "print(\"\\n✓ All models trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eval_header",
   "metadata": {},
   "source": [
    "## Evaluate Models\n",
    "\n",
    "Using RMSE evaluation consistent with other experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a9ecd1-2d14-4538-ba51-4a0264de99b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(user_id, movie_id):\n",
    "    try:\n",
    "        return prediction_matrix.loc[user_id, movie_id]\n",
    "    except (KeyError, IndexError):\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "evaluate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate each model\n",
    "results = []\n",
    "\n",
    "for k, predictions in models.items():\n",
    "    print(f\"Evaluating k={k}...\")\n",
    "    predict_fn = create_predict_fn(predictions)\n",
    "    rmse = evaluate_rmse(test=test, predict_fn=predict)\n",
    "    \n",
    "    results.append({\n",
    "        'k': k,\n",
    "        'RMSE': rmse\n",
    "    })\n",
    "    print(f\"  RMSE: {rmse:.4f}\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SVD Results\")\n",
    "print(\"=\"*60)\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viz_header",
   "metadata": {},
   "source": [
    "## Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(results_df['k'], results_df['RMSE'], marker='o', linewidth=2, markersize=8)\n",
    "plt.xlabel('Number of Latent Factors (k)', fontsize=12)\n",
    "plt.ylabel('RMSE', fontsize=12)\n",
    "plt.title('SVD: RMSE vs Number of Latent Factors', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find best k\n",
    "best_k = results_df.loc[results_df['RMSE'].idxmin(), 'k']\n",
    "best_rmse = results_df.loc[results_df['RMSE'].idxmin(), 'RMSE']\n",
    "print(f\"\\nBest performance: k={int(best_k)} with RMSE={best_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analysis_header",
   "metadata": {},
   "source": [
    "## Detailed Analysis of Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the best k value\n",
    "best_k = int(results_df.loc[results_df['RMSE'].idxmin(), 'k'])\n",
    "best_predictions = models[best_k]\n",
    "\n",
    "# Analyze prediction distribution\n",
    "print(f\"Analysis for SVD with k={best_k}\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nPrediction statistics:\")\n",
    "print(f\"  Min: {best_predictions.min().min():.2f}\")\n",
    "print(f\"  Max: {best_predictions.max().max():.2f}\")\n",
    "print(f\"  Mean: {best_predictions.mean().mean():.2f}\")\n",
    "print(f\"  Std: {best_predictions.std().std():.2f}\")\n",
    "\n",
    "# Compare with actual ratings\n",
    "print(f\"\\nActual ratings statistics:\")\n",
    "print(f\"  Min: {train_matrix[train_matrix > 0].min().min():.2f}\")\n",
    "print(f\"  Max: {train_matrix.max().max():.2f}\")\n",
    "print(f\"  Mean: {train_matrix[train_matrix > 0].mean().mean():.2f}\")\n",
    "print(f\"  Std: {train_matrix[train_matrix > 0].std().std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sample_predictions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample predictions for a random user\n",
    "sample_user = np.random.choice(train_matrix.index)\n",
    "user_actual = train_matrix.loc[sample_user]\n",
    "user_pred = best_predictions.loc[sample_user]\n",
    "\n",
    "# Get rated movies\n",
    "rated_movies = user_actual[user_actual > 0].sample(min(10, (user_actual > 0).sum()))\n",
    "comparison = pd.DataFrame({\n",
    "    'Actual': rated_movies,\n",
    "    'Predicted': user_pred[rated_movies.index]\n",
    "})\n",
    "\n",
    "print(f\"Sample predictions for User {sample_user}:\")\n",
    "print(comparison)\n",
    "\n",
    "# Calculate correlation\n",
    "corr = comparison['Actual'].corr(comparison['Predicted'])\n",
    "print(f\"\\nCorrelation: {corr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412735ab-0a2c-4bc0-940f-353545fb12a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
