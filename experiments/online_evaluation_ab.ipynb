{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abc6895a-7aa3-4354-a2f8-cc0cfb451f5c",
   "metadata": {},
   "source": [
    "As a unit of randomization, we might consider session-level, user-level, and item-level.\n",
    "The main point is that we don't have session IDs in the dataset. But also, session-level randomization might add cross-exposure bias, which occurs when the same user is exposed to multiple variants during the experiment. For item-level randomization, it would be harder to attribute performance to a certain model (however, such kind of randomization can be applied as interleaving test). Anyway, for simplification and higher precision, for that test, we decided to stop on user-level randomization.\n",
    "\n",
    "As a comparison metric, we chose Click-Through Rate, which will be simulated in our case by the availability of movie ratings in the test dataset. For the quardrail metrics we decided to calculate average rating of recommendations (ARR). ARR will balance the recommendation comparison, ensuring that the quality of recommendations is not suffering while we are optimizing CTR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03bb4d5-d228-42db-bafc-97e1f13f6857",
   "metadata": {},
   "source": [
    "The notebook includes online evaluation simulated on MovieLens dataset. We'll compare two of the most accurate models out of the similarity-based collaborative filtering methods developed in the project: cosine similarity user-based and pearson similarity user-based.\n",
    "\n",
    "The results are shown at the end of the notebook.\n",
    "\n",
    "The results analysis and interpretation are in the final report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "720fcdea-868d-4781-ae97-7f0a0242e73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "sys.path.append(str(PROJECT_ROOT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "72b25056-885e-4de5-bc28-e44a68f8ad66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import stats\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9fa1865-3997-407b-afcb-79a0d830cef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_reading import read_ratings_file\n",
    "from src.evaluation import temporal_split\n",
    "from src.models.similarity_based_cf import predict_rating_cf_user_based, recommend_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c35153-8f5a-4603-8eeb-a4eb94d951ee",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d494e48-f676-4c61-ac02-773de3288dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For similarity-based CF, we would use only the file with the movie ratings, we will not need movie metadata or users' features\n",
    "\n",
    "ratings = read_ratings_file() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0273a013-3bc5-4abe-806f-238e8cf07e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: (900188, 4)\n",
      "Test set size: (100021, 4)\n",
      "Train timeframe: 2000-04-25 23:05:32 - 2000-12-29 23:42:47\n",
      "Test timeframe: 2000-12-29 23:43:34 - 2003-02-28 17:49:50\n"
     ]
    }
   ],
   "source": [
    "# Split on train and test sets by date\n",
    "\n",
    "train, test = temporal_split(ratings, test_ratio=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c049ebd2-924d-4712-b0c5-9912fc37441b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create user_id x movie_id matrix\n",
    "\n",
    "train_prep = train.pivot_table(\n",
    "    index='user_id',\n",
    "    columns='movie_id',\n",
    "    values='rating'\n",
    ")\n",
    "train_prep_ = train_prep.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7248dc4-f9e2-4ac8-a25e-b2c27433ff56",
   "metadata": {},
   "source": [
    "# Experiments with cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f53dad5-dfe0-4d71-a2c2-6256d5ef6586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate user similarity with cosine distance\n",
    "\n",
    "user_sim_cos = pd.DataFrame(\n",
    "    cosine_similarity(train_prep_),\n",
    "    index=train_prep.index,\n",
    "    columns=train_prep.index\n",
    ")\n",
    "\n",
    "# Let's calculate user similarity with pearson similarity\n",
    "\n",
    "user_sim_pearson = pd.DataFrame(\n",
    "    cosine_similarity(\n",
    "        train_prep.sub(train_prep.mean(axis=1), axis=0)\\\n",
    "        .fillna(0)\\\n",
    "        .values\n",
    "    ),\n",
    "    index=train_prep.index,\n",
    "    columns=train_prep.index\n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8fdf124-7600-4581-ba2e-046f934c3f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New test set shape is: (95723, 4)\n"
     ]
    }
   ],
   "source": [
    "# From the test set, let's remove users and movies missing in the train set, as similarity based collaborative filtering algorithms don't support cold-start\n",
    "\n",
    "test_users = np.intersect1d(test.user_id.unique(), train.user_id.unique())\n",
    "test_movies = np.intersect1d(test.movie_id.unique(), train.movie_id.unique())\n",
    "\n",
    "test = test[(test.user_id.isin(test_users)) & (test.movie_id.isin(test_movies))]\n",
    "print(f'New test set shape is: {test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c20a56-205b-4605-b332-42a35265ec21",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2aeae583-f3d0-4ac3-b33c-7fc2352e04c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id\n",
       "1587    0.0\n",
       "403     0.0\n",
       "649     0.0\n",
       "2828    0.0\n",
       "2258    0.2\n",
       "       ... \n",
       "5411    0.0\n",
       "5322    0.0\n",
       "5371    0.0\n",
       "2270    0.0\n",
       "5453    0.1\n",
       "Name: ctr, Length: 100, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_size = 100\n",
    "results = pd.DataFrame({\n",
    "    'user_id': np.random.choice(test.user_id.unique(), size=sample_size, replace=False),\n",
    "    'model': np.random.choice(['c', 'p'], size=sample_size)\n",
    "}).set_index('user_id')\n",
    "\n",
    "for user_id, row in results.iterrows():\n",
    "    model = row['model']\n",
    "\n",
    "    if model == 'c':\n",
    "        rec = recommend_k(\n",
    "            user_id=user_id,\n",
    "            test=test,\n",
    "            predict_fn=predict_rating_cf_user_based,\n",
    "            train_prep=train_prep,\n",
    "            sim_df=user_sim_cos,\n",
    "            n=10, \n",
    "            k=10\n",
    "        )\n",
    "    elif model == 'p':\n",
    "        rec = recommend_k(\n",
    "            user_id=user_id,\n",
    "            test=test,\n",
    "            predict_fn=predict_rating_cf_user_based,\n",
    "            train_prep=train_prep,\n",
    "            sim_df=user_sim_pearson,\n",
    "            n=10, \n",
    "            k=10\n",
    "        )\n",
    "    else:\n",
    "        rec = []\n",
    "        \n",
    "    fact = test[test.user_id == user_id].movie_id.values\n",
    "    relevant = np.intersect1d(rec, fact)\n",
    "\n",
    "    ctr = len(relevant) / 10\n",
    "    arr = test[(test.user_id == user_id) & test.movie_id.isin(relevant)\n",
    "        ].rating.mean()\n",
    "\n",
    "    results.loc[[user_id], ['ctr', 'arr']] = ctr, arr\n",
    "\n",
    "results.ctr.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9a192f91-9f62-40ac-a7c0-a3d4c18b8fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttest(column_name: str, results: pd.DataFrame = results, alpha: float = 0.05):\n",
    "    cos = results[results['model'] == 'c'][column_name].dropna()\n",
    "    pearson = results[results['model'] == 'p'][column_name].dropna()\n",
    "    print(f'Cosine similarity user-based model {column_name.upper()}: {cos.mean():.4f}')\n",
    "    print(f'Pearson similarity user-based model {column_name.upper()}: {pearson.mean():.4f}')\n",
    "    print(f'Metric difference: {(cos.mean() - pearson.mean()):.4f}')\n",
    "\n",
    "    t_stat, p_value = stats.ttest_ind(cos, pearson, equal_var=False)\n",
    "    print(f'T-statistic: {t_stat:.4f}')\n",
    "    print(f'P-value: {p_value:.4f}')\n",
    "\n",
    "    if p_value < alpha:\n",
    "        print('Statistically significant difference')\n",
    "    else:\n",
    "        print('No statistically significant difference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "800aed41-fd65-46e4-ae6e-f11e163e3b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity user-based model CTR: 0.0980\n",
      "Pearson similarity user-based model CTR: 0.0294\n",
      "Metric difference: 0.0685\n",
      "T-statistic: 2.8659\n",
      "P-value: 0.0051\n",
      "Statistically significant difference\n"
     ]
    }
   ],
   "source": [
    "ttest('ctr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "295c935b-b78c-4bf5-bcc5-750b2a35089c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity user-based model ARR: 4.4750\n",
      "Pearson similarity user-based model ARR: 4.6190\n",
      "Metric difference: -0.1440\n",
      "T-statistic: -0.5082\n",
      "P-value: 0.6314\n",
      "No statistically significant difference\n"
     ]
    }
   ],
   "source": [
    "ttest('arr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c1dd5b-e37d-4afa-bc4e-6ac71732f2cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
