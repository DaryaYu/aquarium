{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d03bb4d5-d228-42db-bafc-97e1f13f6857",
   "metadata": {},
   "source": [
    "The notebook includes an online evaluation simulated on the MovieLens dataset using multi-armed bandit strategies. We'll use Îµ-greedy and Thompson Sampling to compare two models: cosine similarity user-based and pearson similarity user-based. Also, we'll estimate static policy results to evaluate against multi-armed bandit strategies. As a comparison metric, we'll use CTR.\n",
    "\n",
    "The results are shown at the end of the notebook.\n",
    "\n",
    "The results analysis and interpretation are in the final report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "720fcdea-868d-4781-ae97-7f0a0242e73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "sys.path.append(str(PROJECT_ROOT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72b25056-885e-4de5-bc28-e44a68f8ad66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import stats\n",
    "from collections import Counter\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9fa1865-3997-407b-afcb-79a0d830cef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_reading import read_ratings_file\n",
    "from src.evaluation import temporal_split\n",
    "from src.models.similarity_based_cf import predict_rating_cf_user_based, recommend_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c35153-8f5a-4603-8eeb-a4eb94d951ee",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d494e48-f676-4c61-ac02-773de3288dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For similarity-based CF, we would use only the file with the movie ratings, we will not need movie metadata or users' features\n",
    "\n",
    "ratings = read_ratings_file() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0273a013-3bc5-4abe-806f-238e8cf07e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: (900188, 4)\n",
      "Test set size: (100021, 4)\n",
      "Train timeframe: 2000-04-25 23:05:32 - 2000-12-29 23:42:47\n",
      "Test timeframe: 2000-12-29 23:43:34 - 2003-02-28 17:49:50\n"
     ]
    }
   ],
   "source": [
    "# Split on train and test sets by date\n",
    "\n",
    "train, test = temporal_split(ratings, test_ratio=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c049ebd2-924d-4712-b0c5-9912fc37441b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create user_id x movie_id matrix\n",
    "\n",
    "train_prep = train.pivot_table(\n",
    "    index='user_id',\n",
    "    columns='movie_id',\n",
    "    values='rating'\n",
    ")\n",
    "train_prep_ = train_prep.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f53dad5-dfe0-4d71-a2c2-6256d5ef6586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate user similarity with cosine distance\n",
    "\n",
    "user_sim_cos = pd.DataFrame(\n",
    "    cosine_similarity(train_prep_),\n",
    "    index=train_prep.index,\n",
    "    columns=train_prep.index\n",
    ")\n",
    "\n",
    "# Let's calculate user similarity with pearson similarity\n",
    "\n",
    "user_sim_pearson = pd.DataFrame(\n",
    "    cosine_similarity(\n",
    "        train_prep.sub(train_prep.mean(axis=1), axis=0)\\\n",
    "        .fillna(0)\\\n",
    "        .values\n",
    "    ),\n",
    "    index=train_prep.index,\n",
    "    columns=train_prep.index\n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8fdf124-7600-4581-ba2e-046f934c3f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New test set shape is: (95723, 4)\n"
     ]
    }
   ],
   "source": [
    "# From the test set, let's remove users and movies missing in the train set, as similarity based collaborative filtering algorithms don't support cold-start\n",
    "\n",
    "test_users = np.intersect1d(test.user_id.unique(), train.user_id.unique())\n",
    "test_movies = np.intersect1d(test.movie_id.unique(), train.movie_id.unique())\n",
    "\n",
    "test = test[(test.user_id.isin(test_users)) & (test.movie_id.isin(test_movies))]\n",
    "print(f'New test set shape is: {test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c20a56-205b-4605-b332-42a35265ec21",
   "metadata": {},
   "source": [
    "# Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33cd2531-f042-4b87-b633-eeb3e968e88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieLensBandit:\n",
    "    def __init__(self, models, strategy='thompson', epsilon=0.1):\n",
    "        self.models = models  # 'cos_user_cf', 'pearson_user_cf'\n",
    "        self.n_arms = len(models)\n",
    "        self.strategy = strategy # 'thompson', 'epsilon'\n",
    "        \n",
    "        # Statistics for calculating CTR\n",
    "        self.clicks = np.zeros(self.n_arms)\n",
    "        self.impressions = np.zeros(self.n_arms)\n",
    "        \n",
    "        # Thompson Sampling parameters\n",
    "        self.alphas = np.ones(self.n_arms) \n",
    "        self.betas = np.ones(self.n_arms)\n",
    "\n",
    "        # E-greedy Epsilon parameter \n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def select_model(self):\n",
    "        if self.strategy == 'epsilon':\n",
    "            if np.random.rand() < self.epsilon:\n",
    "                return np.random.randint(self.n_arms)\n",
    "            # Pick the model with highest historical CTR\n",
    "            ctr = self.clicks / (self.impressions + 1e-6)\n",
    "            return np.argmax(ctr)\n",
    "        \n",
    "        elif self.strategy == 'thompson':\n",
    "            samples = [np.random.beta(self.alphas[i], self.betas[i]) for i in range(self.n_arms)]\n",
    "            return np.argmax(samples)\n",
    "\n",
    "    def update(self, arm_idx, num_relevant, k):\n",
    "        \"\"\"\n",
    "        num_relevant: How many of the K movies were actually clicked.\n",
    "        k: Total movies recommended in this turn.\n",
    "        \"\"\"\n",
    "        self.impressions[arm_idx] += k\n",
    "        self.clicks[arm_idx] += num_relevant\n",
    "        \n",
    "        self.alphas[arm_idx] += num_relevant\n",
    "        self.betas[arm_idx] += (k - num_relevant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7760a1d2-8a48-4a73-8852-33e137bc95ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(bandit, users, truth, k=10):\n",
    "    ctr_results = []\n",
    "    total_relevant = 0\n",
    "    total_shown = 0\n",
    "    chosen_models = []\n",
    "    \n",
    "    for i, user_id in enumerate(users):\n",
    "        # Bandit chooses which model will recommend for the user\n",
    "        arm_idx = bandit.select_model()\n",
    "        chosen_model = bandit.models[arm_idx]\n",
    "        \n",
    "        if chosen_model == 'cos_user_cf':\n",
    "            recs = recommend_k(\n",
    "                user_id=user_id,\n",
    "                test=test,\n",
    "                predict_fn=predict_rating_cf_user_based,\n",
    "                train_prep=train_prep,\n",
    "                sim_df=user_sim_cos,\n",
    "                n=10, \n",
    "                k=10\n",
    "            )\n",
    "        elif chosen_model == 'pearson_user_cf':\n",
    "            recs = recommend_k(\n",
    "            user_id=user_id,\n",
    "            test=test,\n",
    "            predict_fn=predict_rating_cf_user_based,\n",
    "            train_prep=train_prep,\n",
    "            sim_df=user_sim_pearson,\n",
    "            n=10, \n",
    "            k=10\n",
    "        )\n",
    "        else:\n",
    "            print('Wrong model name')\n",
    "        \n",
    "        # Calculate the number of relevant movies out of the recommended by the model picked\n",
    "        liked_movies = truth.get(user_id, set())\n",
    "        relevant_count = len([m for m in recs if m in liked_movies])\n",
    "        \n",
    "        # Update the bandit\n",
    "        bandit.update(arm_idx, relevant_count, k)\n",
    "        \n",
    "        # Track CTR and models chosen\n",
    "        total_relevant += relevant_count\n",
    "        total_shown += k\n",
    "        ctr_results.append(total_relevant / total_shown)\n",
    "        chosen_models.append(chosen_model)\n",
    "        \n",
    "    return ctr_results, chosen_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdcfd398-83e7-45d1-be25-dca0f2e65754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit the number of users to speed up the experiment\n",
    "\n",
    "test_users = np.random.choice(test.user_id.unique(), size=300, replace=False)\n",
    "test_ = test[test.user_id.isin(test_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b93625e-f05f-4a12-bd71-227ac861afd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = test_.groupby('user_id')['movie_id'].apply(set).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d37c87f8-c2ec-417d-9d09-f007e7e8666f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate strategies\n",
    "\n",
    "epsilon_greedy = MovieLensBandit(strategy='epsilon', epsilon=0.1, models = ['cos_user_cf', 'pearson_user_cf'])\n",
    "thompson_samp = MovieLensBandit(strategy='thompson', models = ['cos_user_cf', 'pearson_user_cf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5a1f1fa-1c7c-405d-8fc6-f878cd9d2de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the simulation\n",
    "eps_results, eps_chosen_models = run_experiment(epsilon_greedy, test_users, ground_truth)\n",
    "ts_results, ts_chosen_models = run_experiment(thompson_samp, test_users, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fbf4817-a701-41dc-a3d7-3a783ddce41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's run static policy evaluation on cosine-similarity user-based model\n",
    "\n",
    "static_results = []\n",
    "\n",
    "for user_id in test_.user_id.unique():\n",
    "    recs = recommend_k(\n",
    "        user_id=user_id,\n",
    "        test=test,\n",
    "        predict_fn=predict_rating_cf_user_based,\n",
    "        train_prep=train_prep,\n",
    "        sim_df=user_sim_cos,\n",
    "        n=10, \n",
    "        k=10\n",
    "    )\n",
    "\n",
    "    liked_movies = ground_truth.get(user_id, set())\n",
    "    relevant_count = len([m for m in recs if m in liked_movies])\n",
    "\n",
    "    ctr =  relevant_count / 10\n",
    "\n",
    "    static_results.append(ctr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b89e00-94ca-4da9-839e-55c67c31316c",
   "metadata": {},
   "source": [
    "# Simulation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "40647c50-3815-4d3a-b53a-60510b37d7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean CTR in e-greedy bandits simulation: 0.0927, models distribution: Counter({'cos_user_cf': 287, 'pearson_user_cf': 13})\n"
     ]
    }
   ],
   "source": [
    "# E-greedy results:\n",
    "\n",
    "print(f'Mean CTR in e-greedy bandits simulation: {np.mean(eps_results):.4f}, models distribution: {Counter(eps_chosen_models)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ac2e1192-c943-44f0-b760-cdeed5c4c6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean CTR in Thompson Sampling bandits simulation: 0.0914, models distribution: Counter({'cos_user_cf': 294, 'pearson_user_cf': 6})\n"
     ]
    }
   ],
   "source": [
    "# Thompson Sampling results:\n",
    "\n",
    "print(f'Mean CTR in Thompson Sampling bandits simulation: {np.mean(ts_results):.4f}, models distribution: {Counter(ts_chosen_models)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "502cfe28-0366-4ea1-838f-e0de21ebd6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean CTR in static policy: 0.0917\n"
     ]
    }
   ],
   "source": [
    "# Static policy results:\n",
    "\n",
    "print(f'Mean CTR in static policy: {np.mean(static_results):.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
